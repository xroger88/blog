#+TITLE: Computer Vision
#+author: xroger88
#+tags: vision
#+description: Basic understanding on computer vision

what is computer vision...

* The Ancient Secrets of Computer Vision Lecture by Jeseph Redmon (Darknet/YOLO author)
- see https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p

** DONE Introduction
** DONE Human Vision
** DONE Image Basics
** DONE Resizing, Filtering, and Convolutions
** DONE Edges and Features
** DONE Featrues, Matching, and RANSAC
- Edge Feature Detector (with one-dirctional high gradient)
- Corner Feature Detector (with high gradient in 2 or more directions)
- Affine Transformation (6 DoF, scale/rotation/shear/translation)
- Homographic (Projective) Transformation
  + Reference: https://medium.com/@daniel.j.lenton/part-ii-projective-transformations-in-2d-2e99ac9c7e9f
    a) Shear transformation - scale lamda in one direction, 1/lamda in the other direction, eg. transform square box to paralellogram
    b) Elation transformation - scale a fucntion of x and y, meaning scale toward or away from the orgin
    c) Projecting between planes - these 8 DOF transformations (aka projective transformation) are useufl for "projecting" between difference 2D planes located in 3D space. In a single point of projection like the sun, there are two planes transformable, for example, the side of building and the corresponding shadow on the ground.
- SIFT (Scale-Invariant Feature Transform)
** BACK Optical Flow
CLOSED: [2022-04-13 Wed 11:39]
- Movement, related to time. Motion Estimation, Object Tracking, Visual Odometry
- Feature Matching is not enough, not practical for detecting moving parts
- Lucas-Kanade Optical Flow

** BACK 3D, Depth Perception, and Stero
CLOSED: [2022-04-13 Wed 11:39]
** BACK Machine Learning for Computer Vision (2 parts)
CLOSED: [2022-04-13 Wed 11:39]
- Unsupervised learning: K-means clustering
- Supervised learning
  + Pick a model, a loss function
  + Pick model parameters to minimize loss
- Regression predicts real-valued output, use MSE as loss function
- Classification predicts category output, use log likelihood, cross-entropy as loss function
- Bias and Variance !!!
  + linear regression model is high bias (assuming data) but low variance (not sensetive to trained data)
  + nearest regression model is low bias but high variance
- Viola-Jones Face Detection
  + Haar features
  + Boosting: combination of week classifiers, gradient boosting classifier
  + Cascade: series of cheap -> expensive models
    - only run slow, good classifiers on hard examples
- Linear classifier
  + f = w*x + b where w is weights, x is input data, b is bias. Guess w from train data.
  + Logistic regression, f is logistic function, a probability for output (binary classification)
- Stocastic Grediant Decent (GSD)
  + with logistic regression, maximum likelihood of logistic function
- what if we have multiple classes? softmax !!!
  + multinomial logistic regression, a good example is MNIST handwriting classification 0-9
  + support vector machine (SVM), well known ML method
    - for multiple classifier given data, choose best one in terms of maximum margin
    - case study: person detection
    - case study: deformable parts models
- what is feature enginerring?
  + arguably the core problem of machine learning
  + ML models work well if there is a clear relationship between the inputs and outputs of the function you are trying to model
- neural network => feature extractor + linear model
- activation function makes the network model non-linear, aka universal approximation theorem
- how to learn ???

** BACK Neural Networks
CLOSED: [2022-04-13 Wed 11:39]
- Forward Propagation
- Backward Propagation
- Activation Function
- Matrix Multiplication for input, hidden, output layers
- Underfitting (boosting) and Overfitting (regularization)

** BACK Convolutional Neural Networks
CLOSED: [2022-04-13 Wed 11:39]
- convolution layer
- im2col: rearrange image before convolution
  + handles kernel size, stride, padding
- pooling layer (downsampling) -- image is so big! downsample it without the loss of information
  + 2x2 max/mean pooling, stride of 2
- fully connected layer
  + map image features to a single vector

** BACK Network Architecture
CLOSED: [2022-04-13 Wed 11:39]
** BACK Object Detection
CLOSED: [2022-04-13 Wed 11:39]
** BACK Detection and Instance Segmentation
CLOSED: [2022-04-13 Wed 11:39]
- LeNet: First Convnet for Images (Yann LeCun 1998)
- ImageNet: Really big image dataset, 14 million images, 22k categories
  Challenge subset (most used): 1.2M images, 1000 categories
- AlexNet: first good network
- Neural networks work! visualize the result of each layer in network
- VGG: networks getting bigger, from the visual geometry group at oxford
  VGG-16 is still commonly used as a feature extractor
- 3x3 convolution on large image is inefficient, instead 1x1 (downsampling channels) and 3x3 convolutions more efficient
  how many filters per layer is optimal, which is open problem.
- GoogleNet: networks getting weird
  split layers, not just one size, but many 1x1, 3x3, 5x5
  also use 1x1 convs to compress feature maps
  -> Inception Module
  different routes taken ---- split & combine, multiple outputs
- gradient explosion / vanishing problem
  with very deep networks, the gradients flow through many layers of weights on their way back
  with saturating activation functions like logistic or with small wights gradients can "vanish"
  With non-saturating activations or large weights gradients can EXPLODE!
  Learning doesn't scale, what works at 2 levels doesn't at 20
- Batch normalization
  For a mini-batch eg. 64 images, calulate mean, variance over them, then normalize each output by (o-u)/v results in gaussian distribution
  each image's output is being relative to others in the same batch
  They are "good" domain for most of activation functions to stabilize the network
- Residual connections (ResNet)
- Grouped convolutions
  Split up input feature map into groups
  Run convs on groups independently
  Recombine
- Sesmantic Segmentation = Convolution + Deconvolution
- Encoder + Decoder
- U-net / Segnet
- Spatial Pyramid Pooling (SPP)
  max/avg pooling the output of conv into multi-scale downsample versions
- DeepLabv3+
  Atrous convolutions (Dilated convolution)
  the decoder part is pre-trained on ImageNet
- Object Detection
  Scoring object detection -- IOU
  "Correct" bounding box: IOU > 0.5
  Recall: Correct bounding box / total ground-truth boxes
  Precision: Correct bounding box / total predicted boxes
  Only the most confident predictions: high precision, low recall
  all the predictions: low precision, high recall
- Pascal VOC
  One of the first large detection datasets: 20 classes, 11530 training images, 27450 annotated objects
  also used for semantic segmentation!
- Scoring object detection
  Multiple classes, multiple objects per images, can't just use accuracy
  Precision-Recall curve: vary threshold, plot precision and recall
  Average precision: Area under PR curve, only for a single class
  Take mean of AP accross classes: Mean AP(mAP), Standard detection metric, sometimes at particular IOU i.e. mAP@.5 or mAP@.75
- R-CNN (Regions with CNN)
- Tensor encoding detection (P(Object), X, Y, Width, Height, P(Car|Object), ...., P(TV|Object))
- Multiple bounding boxes per cell
  Prior Bound Boxes (small, medium, large) ---> anchor boxes
- Fast RCNN (with ROI pooling), Faster RCNN(with RPN)
- COCO (Common Objects in Context)
  80 objects, 117261 train/val images, 902435 object instances
  New detection metric, mAP averaged over IOU [.5 - .95]
  Segmentation masks for each instance ----
- Instance Segmentation (COCO dataset support this kind of instance label)
  -> Mask R-CNN (IDs assigned per frame)
- Mask R-CNN
- Automatic Caption Generation (COCO dataset has captions on images)

** BACK Vision and Language
CLOSED: [2022-04-13 Wed 11:39]
- Language: Time-series input and output
- Recurrent NN
- GRU (Gated Recurrent Unit)
- LSTM (Long Short Term Memory)
- Next word prediction -- generate story !!!
- Language Translation -- encoder-decoder pattern
- Image captioning  -- encode image and decode it to caption
  How do we score it? that's problem -- BELU, METEOR metric used for automatic scoring
- Visual Question Answering
  Input: Image and a related text-based question
  Output: Answer for the question
- Situation Regcognition
  Images often have on main thing going on, one verb
  Recognize that verb and what sense it's being used in, fill in the other important objects and how they relate in a linguistic frame
- Image Retrieval
  Given a sentence, extract representation using RNN
  Find matching representations from images processed with CNN

** BACK Generative Adaversarial Networks
CLOSED: [2022-04-13 Wed 11:39]
- How to solve any vision problem
  1. pick a neural network architecture
  2. design an encoding of the expected outptut (encoding format is VERY important !!! to make the network simple)
  3. pick a loss function (also VERY important !!!) for that encoding (squared error? Log-likelihood)
  4. Gather a bunch of training data (and lable it)
  5. Train your network with backpropagation for a long time
- Image colorization
  Gray scale images -> colorized images
  not "right" but looks "good"
- Discriminator network
  Real or generated? loss function
- GAN
  real-image -> gray scale image -> generator network -> colorized images
  real-image + generated image -> discriminator network -> real or generated?
  use discriminator loss to improve generator
- pix2pix: paired image modification
- cycle GAN --- style transfering ???
- DCGAN (deep convolutional GAN)
- progressive growing of GANs


* Datasets for computer vision
- https://towardsdatascience.com/getting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b

* Sailent Object Detection
  Survey paper - file:///Users/xroger88/Downloads/Borji2019_Article_SalientObjectDetectionASurvey.pdf

* Apple's Core ML for Mac and iPhone, On-Device AI
- Turi Create by which you can create a model and export it to Core ML
  see https://github.com/apple/turicreate
- see Apple's Core ML materials, https://developer.apple.com/kr/machine-learning/create-ml/
- see https://machinethink.net/blog/

* OpenCV Tutorial by Jason Dsouza (4 Hours course)
- https://www.youtube.com/watch?v=oXlwWbU8l2o

We'll start all the way from the very basics (reading images and video, image transformations, drawing on images) to the more advanced concepts (color spaces, edge detection, and thresholding). Towards the end, we'll be building a Deep Computer Vision model to detect between the characters in "The Simpsons".

⭐️ Code ⭐️
🔗Github link: https://github.com/jasmcaus/opencv-course
🔗Caer: https://github.com/jasmcaus/caer

✏️ Course from Jason Dsouza. Check out his YouTube channel: https://www.youtube.com/jasmcaus

⭐️ Course Contents ⭐️
⌨️ (0:00:00) Introduction
⌨️ (0:01:07) Installing OpenCV and Caer
Section #1 - Basics
⌨️ (0:04:12) Reading Images & Video
⌨️ (0:12:57) Resizing and Rescaling Frames
⌨️ (0:20:21) Drawing Shapes & Putting Text
⌨️ (0:31:55) 5 Essential Functions in OpenCV
⌨️ (0:44:13) Image Transformations
⌨️ (0:57:06) Contour Detection
Section #2 - Advanced
⌨️ (1:12:53) Color Spaces
⌨️ (1:23:10) Color Channels
⌨️ (1:31:03) Blurring
⌨️ (1:44:27) BITWISE operations
⌨️ (1:53:06) Masking
⌨️ (2:01:43) Histogram Computation
⌨️ (2:15:22) Thresholding/Binarizing Images
⌨️ (2:26:27) Edge Detection
Section #3 - Faces:
⌨️ (2:35:25) Face Detection with Haar Cascades
⌨️ (2:49:05) Face Recognition with OpenCV's built-in recognizer
Section #4 - Capstone
⌨️ (3:11:57) Deep Computer Vision

Check out Jason's Deep Learning Crash Course for Beginners: https://www.youtube.com/watch?v=VyWAv...


* OpenCV Python Projects by Murtaza's Workshop - Robotics and AI
- see https://www.youtube.com/playlist?list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q
  + OpenCV Python Tutorials: https://www.youtube.com/playlist?list=PLMoSUbG1Q_r_sc0x7ndCsqdIkL7dwrmNF

** BACK Face Recognition + Attendance Project
CLOSED: [2022-04-13 Wed 11:39]
** BACK Traffic Signs Classification Using Convolution Neural Networks
CLOSED: [2022-04-13 Wed 11:39]
** BACK Real Time Object Measurement
CLOSED: [2022-04-13 Wed 11:39]
** BACK Text Detection usign Neural Networks
CLOSED: [2022-04-13 Wed 11:39]
** BACK Document Scanner
CLOSED: [2022-04-13 Wed 11:39]
** BACK Sudoku Solver
CLOSED: [2022-04-13 Wed 11:39]
** BACK Optical Mark Recognition MCQ Automated Grading
CLOSED: [2022-04-13 Wed 11:39]
** BACK How to detect QRCode and BarCode using OpenCV
CLOSED: [2022-04-13 Wed 11:39]
** BACK Robot Hand Gesture Controlled with Arduino & OpenCV
CLOSED: [2022-04-13 Wed 11:39]
** BACK Robot Arm Arduino Tutorial, Gesture Controlled (Part 1)
CLOSED: [2022-04-13 Wed 11:39]
** BACK Facial Landmarks and Face Filter using OpenCV
CLOSED: [2022-04-13 Wed 11:39]
** BACK Feature Detection and Matching + Image Classifier
CLOSED: [2022-04-13 Wed 11:39]
** BACK Panorama Stitching using OpenCV
CLOSED: [2022-04-13 Wed 11:39]
** BACK Object Detection
CLOSED: [2022-04-13 Wed 11:39]

* Self-Supervised Learning (SSL) for Computer Vision
** SEER: one of the most powerful SSL models for computer vision ever built
paper - https://arxiv.org/pdf/2103.01988.pdf
- 일반화된 지능을 갖기 위해서는 제한된 데이터로 학습하는 것에 한계가 있으며, 많은 이미지 데이터를 정제하여 레이블링을 추가하는 작업에 많은 어려움이 있음.
  다양한 이미지 특징을 사전학습(pre-training)을 시키고, 타겟 도메인에 적용하기 위해 타겟 도메인에 연관된 학습 데이터를 활용하여 모델을 파인튜닝하여 Tranfer Learning을 하는 일련의 과정이 요구됨. SSL 기반으로 사전학습을 어떻게 잘 시킬 수 있을까에 대한 고민임.
  SSL의 경우, 하나의 이미지의 두개의 다른 뷰를 동일 네트워크 입력시켜서 피처 벡터의 차이를 줄이거나 클러스터링 알고리즘을 적용하여 다른 이미지와 상대적으로 멀리, 같은 이미지는 가깝게 배치하는 등의 학습 방법을 사용한다. Joint Embedding, Contrastive Learning, Non-Contrastive Learning 등이 있다.
- 레이블이 없는 랜덤 이미지를 온라인으로 pretraining 시키는 것을 제안, 인스타그램 이미지 활용함.
  기존 방식은 인터넷의 Hashtag를 갖는 이미지만 모아서 해쉬태그를 이용하여 클러스터링하거나, curated 된 ImageNet과 같은 데이터를 기준으로 사전학습을 시킴.
- 규모가 큰 Conv Net 구조인 RegNet 기반으로 large-scale로 학습을 시킴. 모델 파라미터를 늘릴 수 있는 네트워크가 성능에 영향을 주기에, 효율과 성능 고려.
*** 활용에 대한 생각
FAIR에서 공개한 VISSL(https://vissl.ai/) 모델 및 사전학습 결과를 활용하여 다운스트림 태스크에 효과적으로 적용할 수 있는 방안, 즉 사전학습된 네트워크를 활용하여 전이학습이 가능하도록 하면 타켓 도메인에서의 태스크의 성능을 높이는 데 도움이 될 수 있다. 사전학습을 기반으로 전이학습이 가눙하도록 AutoCare ML Framework에서 이를 고려해 보면 좋을 거 같다.
** Hugging Face: a library for computer vision, including such models as Vision Transformer, VisualBERT, and DeIT
- 주어진 문장에서 빠진 단어를 채우는 문제, 즉 전체 컨택스트에 비추어 통계적 상관성을 고려하여 다음 단어를 예측하는 NLP 문제와 대비하여, 비전 문제는 비디오 시퀀스에서 다음 프레임을 예측한다 거나 하나의 프레임에서 일부 픽셀을 예측하는 것으로 복잡도나 상관관계의 폭이 추적 불가능할 정도로 높다.
- NLP 문제에 적용된 솔루션인 트랜스포머 모델을 기반으로 비전 문제를 해결하려는 시도는 앞으로 계속 시도될 것임.
- 다양한 state-of-the-art 트랜스포머 모델(PyTorch, TensorFlow 2.0)의 구현을 제공하며, 구조적으로 사전학습된 모델 클래스, 모델을 빌드하기 위한 설정정보를 가진 Configuration 클래스, 각 모델의 어휘를 저장하고 토큰 임베딩을 위한 스트링 앤코딩/디코딩 방식을 제공하는 트랜스포머 라이브러리임.
- 현재 버전은 컴퓨터 비전에 적용 가능한 여러가지 모델을 포함하고 있다. ViT (Google), VisualBERT (UCLA), DeIT (FAIR) 등.
- NLP Transformer와 같은 프로그래밍 모델을 제공하므로, 쉽게 접근하여 새로운 approach를 테스트해 볼 수 있다.
  ViT를 활용하여 이미지를 분류하는 개념 설명 참조.
#+ATTR_HTML: :width 800
[[https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F076126e7-a169-46af-9cf3-ad2134813913_1600x1100.gif]]
*** 활용애 대한 생각
잘 구성된 정리된 라이브러리를 활용하여 Transformer 기반 비전 인식에 대한 Follow-up이 필요함.
추후 AutoCare ML Framework 확장요소로 고려될 필요가 있음.
