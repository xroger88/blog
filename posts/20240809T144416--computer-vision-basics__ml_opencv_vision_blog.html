title: Computer Vision Basics
date: <2020-10-21 Wed 14:44>
tags: ml,opencv,vision
---
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org8d3b75c">1. The Ancient Secrets of Computer Vision Lecture by Jeseph Redmon (Darknet/YOLO author)</a>
<ul>
<li><a href="#org397609e">1.1. <span class="done DONE">DONE</span> Introduction</a></li>
<li><a href="#org530a863">1.2. <span class="done DONE">DONE</span> Human Vision</a></li>
<li><a href="#orgb0574cd">1.3. <span class="done DONE">DONE</span> Image Basics</a></li>
<li><a href="#orgde1bbe3">1.4. <span class="done DONE">DONE</span> Resizing, Filtering, and Convolutions</a></li>
<li><a href="#org7f86db2">1.5. <span class="done DONE">DONE</span> Edges and Features</a></li>
<li><a href="#orgbef21e1">1.6. <span class="done DONE">DONE</span> Featrues, Matching, and RANSAC</a></li>
<li><a href="#org5e8f327">1.7. <span class="done BACK">BACK</span> Optical Flow</a></li>
<li><a href="#org30a276c">1.8. <span class="done BACK">BACK</span> 3D, Depth Perception, and Stero</a></li>
<li><a href="#org7e59972">1.9. <span class="done BACK">BACK</span> Machine Learning for Computer Vision (2 parts)</a></li>
<li><a href="#org84fcf92">1.10. <span class="done BACK">BACK</span> Neural Networks</a></li>
<li><a href="#orgfc72a5d">1.11. <span class="done BACK">BACK</span> Convolutional Neural Networks</a></li>
<li><a href="#org4558668">1.12. <span class="done BACK">BACK</span> Network Architecture</a></li>
<li><a href="#org45e67a6">1.13. <span class="done BACK">BACK</span> Object Detection</a></li>
<li><a href="#org8a6a486">1.14. <span class="done BACK">BACK</span> Detection and Instance Segmentation</a></li>
<li><a href="#orgac148a5">1.15. <span class="done BACK">BACK</span> Vision and Language</a></li>
<li><a href="#org8be99b7">1.16. <span class="done BACK">BACK</span> Generative Adaversarial Networks</a></li>
</ul>
</li>
<li><a href="#org1e45f50">2. Datasets for computer vision</a></li>
<li><a href="#org4ea22f0">3. Sailent Object Detection</a></li>
<li><a href="#org6dd26ce">4. Apple's Core ML for Mac and iPhone, On-Device AI</a></li>
<li><a href="#orgaac2a72">5. OpenCV Tutorial by Jason Dsouza (4 Hours course)</a></li>
<li><a href="#orgd835886">6. OpenCV Python Projects by Murtaza's Workshop - Robotics and AI</a>
<ul>
<li><a href="#org1783344">6.1. <span class="done BACK">BACK</span> Face Recognition + Attendance Project</a></li>
<li><a href="#orgb5791b8">6.2. <span class="done BACK">BACK</span> Traffic Signs Classification Using Convolution Neural Networks</a></li>
<li><a href="#orga6e8a05">6.3. <span class="done BACK">BACK</span> Real Time Object Measurement</a></li>
<li><a href="#org31e662b">6.4. <span class="done BACK">BACK</span> Text Detection usign Neural Networks</a></li>
<li><a href="#org741b2b6">6.5. <span class="done BACK">BACK</span> Document Scanner</a></li>
<li><a href="#org19340c4">6.6. <span class="done BACK">BACK</span> Sudoku Solver</a></li>
<li><a href="#org0388632">6.7. <span class="done BACK">BACK</span> Optical Mark Recognition MCQ Automated Grading</a></li>
<li><a href="#orgc4ea7a6">6.8. <span class="done BACK">BACK</span> How to detect QRCode and BarCode using OpenCV</a></li>
<li><a href="#orgd14882b">6.9. <span class="done BACK">BACK</span> Robot Hand Gesture Controlled with Arduino &amp; OpenCV</a></li>
<li><a href="#org9cf2403">6.10. <span class="done BACK">BACK</span> Robot Arm Arduino Tutorial, Gesture Controlled (Part 1)</a></li>
<li><a href="#org7c23240">6.11. <span class="done BACK">BACK</span> Facial Landmarks and Face Filter using OpenCV</a></li>
<li><a href="#orgb0723b7">6.12. <span class="done BACK">BACK</span> Feature Detection and Matching + Image Classifier</a></li>
<li><a href="#org7f99e22">6.13. <span class="done BACK">BACK</span> Panorama Stitching using OpenCV</a></li>
<li><a href="#org92a3e43">6.14. <span class="done BACK">BACK</span> Object Detection</a></li>
</ul>
</li>
<li><a href="#orgd1482d4">7. Self-Supervised Learning (SSL) for Computer Vision</a>
<ul>
<li><a href="#org94ae94d">7.1. SEER: one of the most powerful SSL models for computer vision ever built</a></li>
<li><a href="#org5f7aa4e">7.2. Hugging Face: a library for computer vision, including such models as Vision Transformer, VisualBERT, and DeIT</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
ì»´í“¨í„° ë¹„ì „ ê´€ë ¨ ì´ˆê¸° ìŠ¤í„°ë”” ë‚´ìš©ì…ë‹ˆë‹¤. YOLO ê´€ë ¨ ë‚´ìš© ë° OPENCV ì°¸ì¡°.
</p>

<div id="outline-container-org8d3b75c" class="outline-2">
<h2 id="org8d3b75c"><span class="section-number-2">1.</span> The Ancient Secrets of Computer Vision Lecture by Jeseph Redmon (Darknet/YOLO author)</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>see <a href="https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p">https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p</a></li>
</ul>
</div>

<div id="outline-container-org397609e" class="outline-3">
<h3 id="org397609e"><span class="section-number-3">1.1.</span> <span class="done DONE">DONE</span> Introduction</h3>
</div>
<div id="outline-container-org530a863" class="outline-3">
<h3 id="org530a863"><span class="section-number-3">1.2.</span> <span class="done DONE">DONE</span> Human Vision</h3>
</div>
<div id="outline-container-orgb0574cd" class="outline-3">
<h3 id="orgb0574cd"><span class="section-number-3">1.3.</span> <span class="done DONE">DONE</span> Image Basics</h3>
</div>
<div id="outline-container-orgde1bbe3" class="outline-3">
<h3 id="orgde1bbe3"><span class="section-number-3">1.4.</span> <span class="done DONE">DONE</span> Resizing, Filtering, and Convolutions</h3>
</div>
<div id="outline-container-org7f86db2" class="outline-3">
<h3 id="org7f86db2"><span class="section-number-3">1.5.</span> <span class="done DONE">DONE</span> Edges and Features</h3>
</div>
<div id="outline-container-orgbef21e1" class="outline-3">
<h3 id="orgbef21e1"><span class="section-number-3">1.6.</span> <span class="done DONE">DONE</span> Featrues, Matching, and RANSAC</h3>
<div class="outline-text-3" id="text-1-6">
<ul class="org-ul">
<li>Edge Feature Detector (with one-dirctional high gradient)</li>
<li>Corner Feature Detector (with high gradient in 2 or more directions)</li>
<li>Affine Transformation (6 DoF, scale/rotation/shear/translation)</li>
<li>Homographic (Projective) Transformation
<ul class="org-ul">
<li>Reference: <a href="https://medium.com/@daniel.j.lenton/part-ii-projective-transformations-in-2d-2e99ac9c7e9f">https://medium.com/@daniel.j.lenton/part-ii-projective-transformations-in-2d-2e99ac9c7e9f</a>
a) Shear transformation - scale lamda in one direction, 1/lamda in the other direction, eg. transform square box to paralellogram
b) Elation transformation - scale a fucntion of x and y, meaning scale toward or away from the orgin
c) Projecting between planes - these 8 DOF transformations (aka projective transformation) are useufl for "projecting" between difference 2D planes located in 3D space. In a single point of projection like the sun, there are two planes transformable, for example, the side of building and the corresponding shadow on the ground.</li>
</ul></li>
<li>SIFT (Scale-Invariant Feature Transform)</li>
</ul>
</div>
</div>
<div id="outline-container-org5e8f327" class="outline-3">
<h3 id="org5e8f327"><span class="section-number-3">1.7.</span> <span class="done BACK">BACK</span> Optical Flow</h3>
<div class="outline-text-3" id="text-1-7">
<ul class="org-ul">
<li>Movement, related to time. Motion Estimation, Object Tracking, Visual Odometry</li>
<li>Feature Matching is not enough, not practical for detecting moving parts</li>
<li>Lucas-Kanade Optical Flow</li>
</ul>
</div>
</div>

<div id="outline-container-org30a276c" class="outline-3">
<h3 id="org30a276c"><span class="section-number-3">1.8.</span> <span class="done BACK">BACK</span> 3D, Depth Perception, and Stero</h3>
<div class="outline-text-3" id="text-1-8">
</div>
</div>
<div id="outline-container-org7e59972" class="outline-3">
<h3 id="org7e59972"><span class="section-number-3">1.9.</span> <span class="done BACK">BACK</span> Machine Learning for Computer Vision (2 parts)</h3>
<div class="outline-text-3" id="text-1-9">
<ul class="org-ul">
<li>Unsupervised learning: K-means clustering</li>
<li>Supervised learning
<ul class="org-ul">
<li>Pick a model, a loss function</li>
<li>Pick model parameters to minimize loss</li>
</ul></li>
<li>Regression predicts real-valued output, use MSE as loss function</li>
<li>Classification predicts category output, use log likelihood, cross-entropy as loss function</li>
<li>Bias and Variance !!!
<ul class="org-ul">
<li>linear regression model is high bias (assuming data) but low variance (not sensetive to trained data)</li>
<li>nearest regression model is low bias but high variance</li>
</ul></li>
<li>Viola-Jones Face Detection
<ul class="org-ul">
<li>Haar features</li>
<li>Boosting: combination of week classifiers, gradient boosting classifier</li>
<li>Cascade: series of cheap -&gt; expensive models
<ul class="org-ul">
<li>only run slow, good classifiers on hard examples</li>
</ul></li>
</ul></li>
<li>Linear classifier
<ul class="org-ul">
<li>f = w*x + b where w is weights, x is input data, b is bias. Guess w from train data.</li>
<li>Logistic regression, f is logistic function, a probability for output (binary classification)</li>
</ul></li>
<li>Stocastic Grediant Decent (GSD)
<ul class="org-ul">
<li>with logistic regression, maximum likelihood of logistic function</li>
</ul></li>
<li>what if we have multiple classes? softmax !!!
<ul class="org-ul">
<li>multinomial logistic regression, a good example is MNIST handwriting classification 0-9</li>
<li>support vector machine (SVM), well known ML method
<ul class="org-ul">
<li>for multiple classifier given data, choose best one in terms of maximum margin</li>
<li>case study: person detection</li>
<li>case study: deformable parts models</li>
</ul></li>
</ul></li>
<li>what is feature enginerring?
<ul class="org-ul">
<li>arguably the core problem of machine learning</li>
<li>ML models work well if there is a clear relationship between the inputs and outputs of the function you are trying to model</li>
</ul></li>
<li>neural network =&gt; feature extractor + linear model</li>
<li>activation function makes the network model non-linear, aka universal approximation theorem</li>
<li>how to learn ???</li>
</ul>
</div>
</div>

<div id="outline-container-org84fcf92" class="outline-3">
<h3 id="org84fcf92"><span class="section-number-3">1.10.</span> <span class="done BACK">BACK</span> Neural Networks</h3>
<div class="outline-text-3" id="text-1-10">
<ul class="org-ul">
<li>Forward Propagation</li>
<li>Backward Propagation</li>
<li>Activation Function</li>
<li>Matrix Multiplication for input, hidden, output layers</li>
<li>Underfitting (boosting) and Overfitting (regularization)</li>
</ul>
</div>
</div>

<div id="outline-container-orgfc72a5d" class="outline-3">
<h3 id="orgfc72a5d"><span class="section-number-3">1.11.</span> <span class="done BACK">BACK</span> Convolutional Neural Networks</h3>
<div class="outline-text-3" id="text-1-11">
<ul class="org-ul">
<li>convolution layer</li>
<li>im2col: rearrange image before convolution
<ul class="org-ul">
<li>handles kernel size, stride, padding</li>
</ul></li>
<li>pooling layer (downsampling) &#x2013; image is so big! downsample it without the loss of information
<ul class="org-ul">
<li>2x2 max/mean pooling, stride of 2</li>
</ul></li>
<li>fully connected layer
<ul class="org-ul">
<li>map image features to a single vector</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org4558668" class="outline-3">
<h3 id="org4558668"><span class="section-number-3">1.12.</span> <span class="done BACK">BACK</span> Network Architecture</h3>
<div class="outline-text-3" id="text-1-12">
</div>
</div>
<div id="outline-container-org45e67a6" class="outline-3">
<h3 id="org45e67a6"><span class="section-number-3">1.13.</span> <span class="done BACK">BACK</span> Object Detection</h3>
<div class="outline-text-3" id="text-1-13">
</div>
</div>
<div id="outline-container-org8a6a486" class="outline-3">
<h3 id="org8a6a486"><span class="section-number-3">1.14.</span> <span class="done BACK">BACK</span> Detection and Instance Segmentation</h3>
<div class="outline-text-3" id="text-1-14">
<ul class="org-ul">
<li>LeNet: First Convnet for Images (Yann LeCun 1998)</li>
<li>ImageNet: Really big image dataset, 14 million images, 22k categories
Challenge subset (most used): 1.2M images, 1000 categories</li>
<li>AlexNet: first good network</li>
<li>Neural networks work! visualize the result of each layer in network</li>
<li>VGG: networks getting bigger, from the visual geometry group at oxford
VGG-16 is still commonly used as a feature extractor</li>
<li>3x3 convolution on large image is inefficient, instead 1x1 (downsampling channels) and 3x3 convolutions more efficient
how many filters per layer is optimal, which is open problem.</li>
<li>GoogleNet: networks getting weird
split layers, not just one size, but many 1x1, 3x3, 5x5
also use 1x1 convs to compress feature maps
-&gt; Inception Module
different routes taken -&#x2014; split &amp; combine, multiple outputs</li>
<li>gradient explosion / vanishing problem
with very deep networks, the gradients flow through many layers of weights on their way back
with saturating activation functions like logistic or with small wights gradients can "vanish"
With non-saturating activations or large weights gradients can EXPLODE!
Learning doesn't scale, what works at 2 levels doesn't at 20</li>
<li>Batch normalization
For a mini-batch eg. 64 images, calulate mean, variance over them, then normalize each output by (o-u)/v results in gaussian distribution
each image's output is being relative to others in the same batch
They are "good" domain for most of activation functions to stabilize the network</li>
<li>Residual connections (ResNet)</li>
<li>Grouped convolutions
Split up input feature map into groups
Run convs on groups independently
Recombine</li>
<li>Sesmantic Segmentation = Convolution + Deconvolution</li>
<li>Encoder + Decoder</li>
<li>U-net / Segnet</li>
<li>Spatial Pyramid Pooling (SPP)
max/avg pooling the output of conv into multi-scale downsample versions</li>
<li>DeepLabv3+
Atrous convolutions (Dilated convolution)
the decoder part is pre-trained on ImageNet</li>
<li>Object Detection
Scoring object detection &#x2013; IOU
"Correct" bounding box: IOU &gt; 0.5
Recall: Correct bounding box / total ground-truth boxes
Precision: Correct bounding box / total predicted boxes
Only the most confident predictions: high precision, low recall
all the predictions: low precision, high recall</li>
<li>Pascal VOC
One of the first large detection datasets: 20 classes, 11530 training images, 27450 annotated objects
also used for semantic segmentation!</li>
<li>Scoring object detection
Multiple classes, multiple objects per images, can't just use accuracy
Precision-Recall curve: vary threshold, plot precision and recall
Average precision: Area under PR curve, only for a single class
Take mean of AP accross classes: Mean AP(mAP), Standard detection metric, sometimes at particular IOU i.e. mAP@.5 or mAP@.75</li>
<li>R-CNN (Regions with CNN)</li>
<li>Tensor encoding detection (P(Object), X, Y, Width, Height, P(Car|Object), &#x2026;., P(TV|Object))</li>
<li>Multiple bounding boxes per cell
Prior Bound Boxes (small, medium, large) &#x2014;&gt; anchor boxes</li>
<li>Fast RCNN (with ROI pooling), Faster RCNN(with RPN)</li>
<li>COCO (Common Objects in Context)
80 objects, 117261 train/val images, 902435 object instances
New detection metric, mAP averaged over IOU [.5 - .95]
Segmentation masks for each instance -&#x2014;</li>
<li>Instance Segmentation (COCO dataset support this kind of instance label)
-&gt; Mask R-CNN (IDs assigned per frame)</li>
<li>Mask R-CNN</li>
<li>Automatic Caption Generation (COCO dataset has captions on images)</li>
</ul>
</div>
</div>

<div id="outline-container-orgac148a5" class="outline-3">
<h3 id="orgac148a5"><span class="section-number-3">1.15.</span> <span class="done BACK">BACK</span> Vision and Language</h3>
<div class="outline-text-3" id="text-1-15">
<ul class="org-ul">
<li>Language: Time-series input and output</li>
<li>Recurrent NN</li>
<li>GRU (Gated Recurrent Unit)</li>
<li>LSTM (Long Short Term Memory)</li>
<li>Next word prediction &#x2013; generate story !!!</li>
<li>Language Translation &#x2013; encoder-decoder pattern</li>
<li>Image captioning  &#x2013; encode image and decode it to caption
How do we score it? that's problem &#x2013; BELU, METEOR metric used for automatic scoring</li>
<li>Visual Question Answering
Input: Image and a related text-based question
Output: Answer for the question</li>
<li>Situation Regcognition
Images often have on main thing going on, one verb
Recognize that verb and what sense it's being used in, fill in the other important objects and how they relate in a linguistic frame</li>
<li>Image Retrieval
Given a sentence, extract representation using RNN
Find matching representations from images processed with CNN</li>
</ul>
</div>
</div>

<div id="outline-container-org8be99b7" class="outline-3">
<h3 id="org8be99b7"><span class="section-number-3">1.16.</span> <span class="done BACK">BACK</span> Generative Adaversarial Networks</h3>
<div class="outline-text-3" id="text-1-16">
<ul class="org-ul">
<li>How to solve any vision problem
<ol class="org-ol">
<li>pick a neural network architecture</li>
<li>design an encoding of the expected outptut (encoding format is VERY important !!! to make the network simple)</li>
<li>pick a loss function (also VERY important !!!) for that encoding (squared error? Log-likelihood)</li>
<li>Gather a bunch of training data (and lable it)</li>
<li>Train your network with backpropagation for a long time</li>
</ol></li>
<li>Image colorization
Gray scale images -&gt; colorized images
not "right" but looks "good"</li>
<li>Discriminator network
Real or generated? loss function</li>
<li>GAN
real-image -&gt; gray scale image -&gt; generator network -&gt; colorized images
real-image + generated image -&gt; discriminator network -&gt; real or generated?
use discriminator loss to improve generator</li>
<li>pix2pix: paired image modification</li>
<li>cycle GAN &#x2014; style transfering ???</li>
<li>DCGAN (deep convolutional GAN)</li>
<li>progressive growing of GANs</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org1e45f50" class="outline-2">
<h2 id="org1e45f50"><span class="section-number-2">2.</span> Datasets for computer vision</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li><a href="https://towardsdatascience.com/getting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b">https://towardsdatascience.com/getting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b</a></li>
</ul>
</div>
</div>

<div id="outline-container-org4ea22f0" class="outline-2">
<h2 id="org4ea22f0"><span class="section-number-2">3.</span> Sailent Object Detection</h2>
</div>

<div id="outline-container-org6dd26ce" class="outline-2">
<h2 id="org6dd26ce"><span class="section-number-2">4.</span> Apple's Core ML for Mac and iPhone, On-Device AI</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li>Turi Create by which you can create a model and export it to Core ML
see <a href="https://github.com/apple/turicreate">https://github.com/apple/turicreate</a></li>
<li>see Apple's Core ML materials, <a href="https://developer.apple.com/kr/machine-learning/create-ml/">https://developer.apple.com/kr/machine-learning/create-ml/</a></li>
<li>see <a href="https://machinethink.net/blog/">https://machinethink.net/blog/</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgaac2a72" class="outline-2">
<h2 id="orgaac2a72"><span class="section-number-2">5.</span> OpenCV Tutorial by Jason Dsouza (4 Hours course)</h2>
<div class="outline-text-2" id="text-5">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=oXlwWbU8l2o">https://www.youtube.com/watch?v=oXlwWbU8l2o</a></li>
</ul>

<p>
We'll start all the way from the very basics (reading images and video, image transformations, drawing on images) to the more advanced concepts (color spaces, edge detection, and thresholding). Towards the end, we'll be building a Deep Computer Vision model to detect between the characters in "The Simpsons".
</p>

<p>
â­ï¸ Code â­ï¸
ğŸ”—Github link: <a href="https://github.com/jasmcaus/opencv-course">https://github.com/jasmcaus/opencv-course</a>
ğŸ”—Caer: <a href="https://github.com/jasmcaus/caer">https://github.com/jasmcaus/caer</a>
</p>

<p>
âœï¸ Course from Jason Dsouza. Check out his YouTube channel: <a href="https://www.youtube.com/jasmcaus">https://www.youtube.com/jasmcaus</a>
</p>

<p>
â­ï¸ Course Contents â­ï¸
âŒ¨ï¸ (0:00:00) Introduction
âŒ¨ï¸ (0:01:07) Installing OpenCV and Caer
Section #1 - Basics
âŒ¨ï¸ (0:04:12) Reading Images &amp; Video
âŒ¨ï¸ (0:12:57) Resizing and Rescaling Frames
âŒ¨ï¸ (0:20:21) Drawing Shapes &amp; Putting Text
âŒ¨ï¸ (0:31:55) 5 Essential Functions in OpenCV
âŒ¨ï¸ (0:44:13) Image Transformations
âŒ¨ï¸ (0:57:06) Contour Detection
Section #2 - Advanced
âŒ¨ï¸ (1:12:53) Color Spaces
âŒ¨ï¸ (1:23:10) Color Channels
âŒ¨ï¸ (1:31:03) Blurring
âŒ¨ï¸ (1:44:27) BITWISE operations
âŒ¨ï¸ (1:53:06) Masking
âŒ¨ï¸ (2:01:43) Histogram Computation
âŒ¨ï¸ (2:15:22) Thresholding/Binarizing Images
âŒ¨ï¸ (2:26:27) Edge Detection
Section #3 - Faces:
âŒ¨ï¸ (2:35:25) Face Detection with Haar Cascades
âŒ¨ï¸ (2:49:05) Face Recognition with OpenCV's built-in recognizer
Section #4 - Capstone
âŒ¨ï¸ (3:11:57) Deep Computer Vision
</p>

<p>
Check out Jason's Deep Learning Crash Course for Beginners: <a href="https://www.youtube.com/watch?v=VyWAv">https://www.youtube.com/watch?v=VyWAv</a>&#x2026;
</p>
</div>
</div>


<div id="outline-container-orgd835886" class="outline-2">
<h2 id="orgd835886"><span class="section-number-2">6.</span> OpenCV Python Projects by Murtaza's Workshop - Robotics and AI</h2>
<div class="outline-text-2" id="text-6">
<ul class="org-ul">
<li>see <a href="https://www.youtube.com/playlist?list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q">https://www.youtube.com/playlist?list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q</a>
<ul class="org-ul">
<li>OpenCV Python Tutorials: <a href="https://www.youtube.com/playlist?list=PLMoSUbG1Q_r_sc0x7ndCsqdIkL7dwrmNF">https://www.youtube.com/playlist?list=PLMoSUbG1Q_r_sc0x7ndCsqdIkL7dwrmNF</a></li>
</ul></li>
</ul>
</div>

<div id="outline-container-org1783344" class="outline-3">
<h3 id="org1783344"><span class="section-number-3">6.1.</span> <span class="done BACK">BACK</span> Face Recognition + Attendance Project</h3>
<div class="outline-text-3" id="text-6-1">
</div>
</div>
<div id="outline-container-orgb5791b8" class="outline-3">
<h3 id="orgb5791b8"><span class="section-number-3">6.2.</span> <span class="done BACK">BACK</span> Traffic Signs Classification Using Convolution Neural Networks</h3>
<div class="outline-text-3" id="text-6-2">
</div>
</div>
<div id="outline-container-orga6e8a05" class="outline-3">
<h3 id="orga6e8a05"><span class="section-number-3">6.3.</span> <span class="done BACK">BACK</span> Real Time Object Measurement</h3>
<div class="outline-text-3" id="text-6-3">
</div>
</div>
<div id="outline-container-org31e662b" class="outline-3">
<h3 id="org31e662b"><span class="section-number-3">6.4.</span> <span class="done BACK">BACK</span> Text Detection usign Neural Networks</h3>
<div class="outline-text-3" id="text-6-4">
</div>
</div>
<div id="outline-container-org741b2b6" class="outline-3">
<h3 id="org741b2b6"><span class="section-number-3">6.5.</span> <span class="done BACK">BACK</span> Document Scanner</h3>
<div class="outline-text-3" id="text-6-5">
</div>
</div>
<div id="outline-container-org19340c4" class="outline-3">
<h3 id="org19340c4"><span class="section-number-3">6.6.</span> <span class="done BACK">BACK</span> Sudoku Solver</h3>
<div class="outline-text-3" id="text-6-6">
</div>
</div>
<div id="outline-container-org0388632" class="outline-3">
<h3 id="org0388632"><span class="section-number-3">6.7.</span> <span class="done BACK">BACK</span> Optical Mark Recognition MCQ Automated Grading</h3>
<div class="outline-text-3" id="text-6-7">
</div>
</div>
<div id="outline-container-orgc4ea7a6" class="outline-3">
<h3 id="orgc4ea7a6"><span class="section-number-3">6.8.</span> <span class="done BACK">BACK</span> How to detect QRCode and BarCode using OpenCV</h3>
<div class="outline-text-3" id="text-6-8">
</div>
</div>
<div id="outline-container-orgd14882b" class="outline-3">
<h3 id="orgd14882b"><span class="section-number-3">6.9.</span> <span class="done BACK">BACK</span> Robot Hand Gesture Controlled with Arduino &amp; OpenCV</h3>
<div class="outline-text-3" id="text-6-9">
</div>
</div>
<div id="outline-container-org9cf2403" class="outline-3">
<h3 id="org9cf2403"><span class="section-number-3">6.10.</span> <span class="done BACK">BACK</span> Robot Arm Arduino Tutorial, Gesture Controlled (Part 1)</h3>
<div class="outline-text-3" id="text-6-10">
</div>
</div>
<div id="outline-container-org7c23240" class="outline-3">
<h3 id="org7c23240"><span class="section-number-3">6.11.</span> <span class="done BACK">BACK</span> Facial Landmarks and Face Filter using OpenCV</h3>
<div class="outline-text-3" id="text-6-11">
</div>
</div>
<div id="outline-container-orgb0723b7" class="outline-3">
<h3 id="orgb0723b7"><span class="section-number-3">6.12.</span> <span class="done BACK">BACK</span> Feature Detection and Matching + Image Classifier</h3>
<div class="outline-text-3" id="text-6-12">
</div>
</div>
<div id="outline-container-org7f99e22" class="outline-3">
<h3 id="org7f99e22"><span class="section-number-3">6.13.</span> <span class="done BACK">BACK</span> Panorama Stitching using OpenCV</h3>
<div class="outline-text-3" id="text-6-13">
</div>
</div>
<div id="outline-container-org92a3e43" class="outline-3">
<h3 id="org92a3e43"><span class="section-number-3">6.14.</span> <span class="done BACK">BACK</span> Object Detection</h3>
<div class="outline-text-3" id="text-6-14">
</div>
</div>
</div>

<div id="outline-container-orgd1482d4" class="outline-2">
<h2 id="orgd1482d4"><span class="section-number-2">7.</span> Self-Supervised Learning (SSL) for Computer Vision</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org94ae94d" class="outline-3">
<h3 id="org94ae94d"><span class="section-number-3">7.1.</span> SEER: one of the most powerful SSL models for computer vision ever built</h3>
<div class="outline-text-3" id="text-7-1">
<p>
paper - <a href="https://arxiv.org/pdf/2103.01988.pdf">https://arxiv.org/pdf/2103.01988.pdf</a>
</p>
<ul class="org-ul">
<li>ì¼ë°˜í™”ëœ ì§€ëŠ¥ì„ ê°–ê¸° ìœ„í•´ì„œëŠ” ì œí•œëœ ë°ì´í„°ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì— í•œê³„ê°€ ìˆìœ¼ë©°, ë§ì€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì •ì œí•˜ì—¬ ë ˆì´ë¸”ë§ì„ ì¶”ê°€í•˜ëŠ” ì‘ì—…ì— ë§ì€ ì–´ë ¤ì›€ì´ ìˆìŒ.
ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íŠ¹ì§•ì„ ì‚¬ì „í•™ìŠµ(pre-training)ì„ ì‹œí‚¤ê³ , íƒ€ê²Ÿ ë„ë©”ì¸ì— ì ìš©í•˜ê¸° ìœ„í•´ íƒ€ê²Ÿ ë„ë©”ì¸ì— ì—°ê´€ëœ í•™ìŠµ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ì—¬ Tranfer Learningì„ í•˜ëŠ” ì¼ë ¨ì˜ ê³¼ì •ì´ ìš”êµ¬ë¨. SSL ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì „í•™ìŠµì„ ì–´ë–»ê²Œ ì˜ ì‹œí‚¬ ìˆ˜ ìˆì„ê¹Œì— ëŒ€í•œ ê³ ë¯¼ì„.
SSLì˜ ê²½ìš°, í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì˜ ë‘ê°œì˜ ë‹¤ë¥¸ ë·°ë¥¼ ë™ì¼ ë„¤íŠ¸ì›Œí¬ ì…ë ¥ì‹œì¼œì„œ í”¼ì²˜ ë²¡í„°ì˜ ì°¨ì´ë¥¼ ì¤„ì´ê±°ë‚˜ í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë‹¤ë¥¸ ì´ë¯¸ì§€ì™€ ìƒëŒ€ì ìœ¼ë¡œ ë©€ë¦¬, ê°™ì€ ì´ë¯¸ì§€ëŠ” ê°€ê¹ê²Œ ë°°ì¹˜í•˜ëŠ” ë“±ì˜ í•™ìŠµ ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤. Joint Embedding, Contrastive Learning, Non-Contrastive Learning ë“±ì´ ìˆë‹¤.</li>
<li>ë ˆì´ë¸”ì´ ì—†ëŠ” ëœë¤ ì´ë¯¸ì§€ë¥¼ ì˜¨ë¼ì¸ìœ¼ë¡œ pretraining ì‹œí‚¤ëŠ” ê²ƒì„ ì œì•ˆ, ì¸ìŠ¤íƒ€ê·¸ë¨ ì´ë¯¸ì§€ í™œìš©í•¨.
ê¸°ì¡´ ë°©ì‹ì€ ì¸í„°ë„·ì˜ Hashtagë¥¼ ê°–ëŠ” ì´ë¯¸ì§€ë§Œ ëª¨ì•„ì„œ í•´ì‰¬íƒœê·¸ë¥¼ ì´ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§í•˜ê±°ë‚˜, curated ëœ ImageNetê³¼ ê°™ì€ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ì „í•™ìŠµì„ ì‹œí‚´.</li>
<li>ê·œëª¨ê°€ í° Conv Net êµ¬ì¡°ì¸ RegNet ê¸°ë°˜ìœ¼ë¡œ large-scaleë¡œ í•™ìŠµì„ ì‹œí‚´. ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ëŠ˜ë¦´ ìˆ˜ ìˆëŠ” ë„¤íŠ¸ì›Œí¬ê°€ ì„±ëŠ¥ì— ì˜í–¥ì„ ì£¼ê¸°ì—, íš¨ìœ¨ê³¼ ì„±ëŠ¥ ê³ ë ¤.</li>
</ul>
</div>
<div id="outline-container-org22b6c86" class="outline-4">
<h4 id="org22b6c86"><span class="section-number-4">7.1.1.</span> í™œìš©ì— ëŒ€í•œ ìƒê°</h4>
<div class="outline-text-4" id="text-7-1-1">
<p>
FAIRì—ì„œ ê³µê°œí•œ VISSL(<a href="https://vissl.ai/">https://vissl.ai/</a>) ëª¨ë¸ ë° ì‚¬ì „í•™ìŠµ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆ, ì¦‰ ì‚¬ì „í•™ìŠµëœ ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ì „ì´í•™ìŠµì´ ê°€ëŠ¥í•˜ë„ë¡ í•˜ë©´ íƒ€ì¼“ ë„ë©”ì¸ì—ì„œì˜ íƒœìŠ¤í¬ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤. ì‚¬ì „í•™ìŠµì„ ê¸°ë°˜ìœ¼ë¡œ ì „ì´í•™ìŠµì´ ê°€ëˆ™í•˜ë„ë¡ AutoCare ML Frameworkì—ì„œ ì´ë¥¼ ê³ ë ¤í•´ ë³´ë©´ ì¢‹ì„ ê±° ê°™ë‹¤.
</p>
</div>
</div>
</div>
<div id="outline-container-org5f7aa4e" class="outline-3">
<h3 id="org5f7aa4e"><span class="section-number-3">7.2.</span> Hugging Face: a library for computer vision, including such models as Vision Transformer, VisualBERT, and DeIT</h3>
<div class="outline-text-3" id="text-7-2">
<ul class="org-ul">
<li>ì£¼ì–´ì§„ ë¬¸ì¥ì—ì„œ ë¹ ì§„ ë‹¨ì–´ë¥¼ ì±„ìš°ëŠ” ë¬¸ì œ, ì¦‰ ì „ì²´ ì»¨íƒìŠ¤íŠ¸ì— ë¹„ì¶”ì–´ í†µê³„ì  ìƒê´€ì„±ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” NLP ë¬¸ì œì™€ ëŒ€ë¹„í•˜ì—¬, ë¹„ì „ ë¬¸ì œëŠ” ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ì—ì„œ ë‹¤ìŒ í”„ë ˆì„ì„ ì˜ˆì¸¡í•œë‹¤ ê±°ë‚˜ í•˜ë‚˜ì˜ í”„ë ˆì„ì—ì„œ ì¼ë¶€ í”½ì…€ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³µì¡ë„ë‚˜ ìƒê´€ê´€ê³„ì˜ í­ì´ ì¶”ì  ë¶ˆê°€ëŠ¥í•  ì •ë„ë¡œ ë†’ë‹¤.</li>
<li>NLP ë¬¸ì œì— ì ìš©ëœ ì†”ë£¨ì…˜ì¸ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë¹„ì „ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ëŠ” ì‹œë„ëŠ” ì•ìœ¼ë¡œ ê³„ì† ì‹œë„ë  ê²ƒì„.</li>
<li>ë‹¤ì–‘í•œ state-of-the-art íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸(PyTorch, TensorFlow 2.0)ì˜ êµ¬í˜„ì„ ì œê³µí•˜ë©°, êµ¬ì¡°ì ìœ¼ë¡œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ í´ë˜ìŠ¤, ëª¨ë¸ì„ ë¹Œë“œí•˜ê¸° ìœ„í•œ ì„¤ì •ì •ë³´ë¥¼ ê°€ì§„ Configuration í´ë˜ìŠ¤, ê° ëª¨ë¸ì˜ ì–´íœ˜ë¥¼ ì €ì¥í•˜ê³  í† í° ì„ë² ë”©ì„ ìœ„í•œ ìŠ¤íŠ¸ë§ ì•¤ì½”ë”©/ë””ì½”ë”© ë°©ì‹ì„ ì œê³µí•˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì„.</li>
<li>í˜„ì¬ ë²„ì „ì€ ì»´í“¨í„° ë¹„ì „ì— ì ìš© ê°€ëŠ¥í•œ ì—¬ëŸ¬ê°€ì§€ ëª¨ë¸ì„ í¬í•¨í•˜ê³  ìˆë‹¤. ViT (Google), VisualBERT (UCLA), DeIT (FAIR) ë“±.</li>
<li>NLP Transformerì™€ ê°™ì€ í”„ë¡œê·¸ë˜ë° ëª¨ë¸ì„ ì œê³µí•˜ë¯€ë¡œ, ì‰½ê²Œ ì ‘ê·¼í•˜ì—¬ ìƒˆë¡œìš´ approachë¥¼ í…ŒìŠ¤íŠ¸í•´ ë³¼ ìˆ˜ ìˆë‹¤.
ViTë¥¼ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê°œë… ì„¤ëª… ì°¸ì¡°.</li>
</ul>

<div id="org375d4de" class="figure">
<p><img src="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F076126e7-a169-46af-9cf3-ad2134813913_1600x1100.gif" alt="https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F076126e7-a169-46af-9cf3-ad2134813913_1600x1100.gif" width="800" />
</p>
</div>
</div>
<div id="outline-container-orgb961dc0" class="outline-4">
<h4 id="orgb961dc0"><span class="section-number-4">7.2.1.</span> í™œìš©ì•  ëŒ€í•œ ìƒê°</h4>
<div class="outline-text-4" id="text-7-2-1">
<p>
ì˜ êµ¬ì„±ëœ ì •ë¦¬ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ Transformer ê¸°ë°˜ ë¹„ì „ ì¸ì‹ì— ëŒ€í•œ Follow-upì´ í•„ìš”í•¨.
ì¶”í›„ AutoCare ML Framework í™•ì¥ìš”ì†Œë¡œ ê³ ë ¤ë  í•„ìš”ê°€ ìˆìŒ.
</p>
</div>
</div>
</div>
</div>
